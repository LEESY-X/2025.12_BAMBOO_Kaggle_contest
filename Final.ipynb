{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27c8cc-4610-40c7-ac97-0a1eb95435f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# 1. 데이터 로드 + 기본 전처리\n",
    "# ==========================================\n",
    "df_train = pd.read_csv('amazonproduct_train.csv')\n",
    "df_test = pd.read_csv('amazonproduct_test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 가격 전처리\n",
    "df_train['Selling Price'] = df_train['Selling Price'].astype(str).str.replace(r'[$,]', '', regex=True)\n",
    "df_train['Selling Price'] = pd.to_numeric(df_train['Selling Price'], errors='coerce')\n",
    "df_train = df_train.dropna(subset=['Selling Price'])\n",
    "y_tr = df_train['Selling Price'].values \n",
    "\n",
    "# 결측치 채우기\n",
    "text_cols = ['Category', 'Product Specification', 'Product Name', 'Description']\n",
    "for col in text_cols:\n",
    "    df_train[col] = df_train[col].fillna('Unknown').astype(str)\n",
    "    df_test[col] = df_test[col].fillna('Unknown').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cb018-d86b-49df-aa5d-fde8a64357aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. 피처 엔지니어링\n",
    "# ==========================================\n",
    "def process_all_features_in_one_pass(row):\n",
    "    spec = str(row['Product Specification'])\n",
    "    name = str(row['Product Name'])\n",
    "\n",
    "    spec_lower = spec.lower()\n",
    "    name_lower = name.lower()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # [A] 수치 정보 추출 (무게, 배송무게, 크기, 연령, 개수)\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "    # 함수: 텍스트에서 숫자+단위 찾아서 lb(파운드)로 변환\n",
    "    def extract_weight(text, pattern_prefix=''):\n",
    "        # pattern_prefix: \"shipping weight\" 같은 특정 문맥 뒤를 찾을 때 사용\n",
    "        w_lb = 0.0\n",
    "        # 정규식: (접두사)...(숫자)...(단위)\n",
    "        # 예: shipping weight: 5.2 pounds\n",
    "        regex_base = pattern_prefix + r':?\\s*(\\d+\\.?\\d*)\\s*'\n",
    "\n",
    "        m_lb = re.search(regex_base + r'(pound|lb)', text)\n",
    "        m_oz = re.search(regex_base + r'(ounce|oz)', text)\n",
    "        m_kg = re.search(regex_base + r'(kg|kilogram)', text)\n",
    "\n",
    "        if m_lb: w_lb = float(m_lb.group(1))\n",
    "        elif m_oz: w_lb = float(m_oz.group(1)) / 16.0\n",
    "        elif m_kg: w_lb = float(m_kg.group(1)) * 2.20462\n",
    "        return w_lb\n",
    "\n",
    "    # 1. Item Weight (제품 무게)\n",
    "    item_weight_lb = extract_weight(spec_lower, r'item\\s*weight')\n",
    "    if item_weight_lb == 0: # item weight 명시가 없으면 일반 패턴 검색\n",
    "        item_weight_lb = extract_weight(spec_lower, r'')\n",
    "\n",
    "    # 2. Shipping Weight (배송 무게)\n",
    "    ship_weight_lb = extract_weight(spec_lower, r'shipping\\s*weight')\n",
    "\n",
    "    # 3. Product Volume (크기 -> 부피 계산) \n",
    "    # 패턴: 10 x 5 x 2 (inches 생략 가능)\n",
    "    vol = 0.0\n",
    "    # \"숫자 x 숫자 x 숫자\" 패턴 찾기\n",
    "    dim_m = re.search(r'(\\d+\\.?\\d*)\\s*x\\s*(\\d+\\.?\\d*)\\s*x\\s*(\\d+\\.?\\d*)', spec_lower)\n",
    "    if dim_m:\n",
    "        try:\n",
    "            # 가로 * 세로 * 높이\n",
    "            vol = float(dim_m.group(1)) * float(dim_m.group(2)) * float(dim_m.group(3))\n",
    "        except:\n",
    "            vol = 0.0\n",
    "\n",
    "    # 4. Age (연령)\n",
    "    min_age = -1.0\n",
    "    age_str = None\n",
    "    age_m = re.search(r'(\\d+)\\s*(year|yr|month)', spec_lower)\n",
    "    if age_m:\n",
    "        val = float(age_m.group(1))\n",
    "        unit = age_m.group(2)\n",
    "        if 'month' in unit: min_age = val / 12.0\n",
    "        else: min_age = val\n",
    "        age_str = f\"{min_age:.1f} years\"\n",
    "\n",
    "    # 5. Pack (수량)\n",
    "    pack_qty = 1.0\n",
    "    pack_m = re.search(r'(\\d+)\\s*(pack|pk|pcs|set|count)', name_lower)\n",
    "    if pack_m: pack_qty = float(pack_m.group(1))\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # [B] BERT용 텍스트 정보 구성 \n",
    "    # ---------------------------------------------------------\n",
    "    extracted_parts = []\n",
    "    brand_col = \"Unknown\"\n",
    "\n",
    "    # Brand\n",
    "    brand_match = re.search(r'(Manufacturer|Brand):?\\s*([^|]+)', spec, re.I)\n",
    "    if brand_match:\n",
    "        found_brand = brand_match.group(2).strip()\n",
    "        extracted_parts.append(f\"Brand: {found_brand}\")\n",
    "        brand_col = found_brand\n",
    "    else:\n",
    "        if len(name) > 0: brand_col = name.split()[0]\n",
    "\n",
    "    # 스펙 텍스트 조립\n",
    "    if item_weight_lb > 0: extracted_parts.append(f\"Weight: {item_weight_lb:.2f} lb\")\n",
    "    if ship_weight_lb > 0: extracted_parts.append(f\"Ship Weight: {ship_weight_lb:.2f} lb\") # 텍스트에도 추가\n",
    "    if vol > 0: extracted_parts.append(f\"Vol: {vol:.2f}\") \n",
    "    if age_str: extracted_parts.append(f\"Age: {age_str}\")\n",
    "\n",
    "    cleaned_spec = \" | \".join(extracted_parts) if extracted_parts else \"Unknown\"\n",
    "\n",
    "    # 반환값에 새로 만든 수치형 변수들(item_weight, ship_weight, vol) 추가\n",
    "    return pd.Series([cleaned_spec, brand_col, min_age, item_weight_lb, ship_weight_lb, vol, pack_qty],\n",
    "                     index=['Cleaned_Spec', 'Brand', 'min_age', 'item_weight_lb', 'ship_weight_lb', 'product_vol', 'pack_qty'])\n",
    "\n",
    "# 적용\n",
    "new_cols = ['Cleaned_Spec', 'Brand', 'min_age', 'item_weight_lb', 'ship_weight_lb', 'product_vol', 'pack_qty']\n",
    "df_train[new_cols] = df_train.apply(process_all_features_in_one_pass, axis=1)\n",
    "df_test[new_cols] = df_test.apply(process_all_features_in_one_pass, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b6bc1-cf06-4980-8069-338c08650c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. 인코딩 및 수치형 변수 정리\n",
    "# ==========================================\n",
    "\n",
    "# 1) 카테고리 세분화\n",
    "def split_category(df):\n",
    "    split_data = df['Category'].str.split('|', n=2, expand=True)\n",
    "    df['Main_Cat'] = split_data[0].fillna('Unknown').str.strip()\n",
    "    df['Sub_Cat'] = split_data[1].fillna('Unknown').str.strip()\n",
    "    df['Deep_Cat'] = split_data[2].fillna('Unknown').str.strip() if split_data.shape[1] > 2 else 'Unknown'\n",
    "    return df\n",
    "\n",
    "df_train = split_category(df_train)\n",
    "df_test = split_category(df_test)\n",
    "\n",
    "# 2) 레이블 인코딩\n",
    "label_cols = ['Brand', 'Main_Cat', 'Sub_Cat', 'Deep_Cat']\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_values = pd.concat([df_train[col], df_test[col]]).astype(str).unique()\n",
    "    le.fit(all_values)\n",
    "    df_train[f'{col}_label'] = le.transform(df_train[col].astype(str))\n",
    "    df_test[f'{col}_label'] = le.transform(df_test[col].astype(str))\n",
    "\n",
    "# 3) 타겟 인코딩 \n",
    "target_cols = ['Brand', 'Main_Cat', 'Sub_Cat', 'Deep_Cat'] \n",
    "global_mean = y_tr.mean()\n",
    "\n",
    "for col in target_cols:\n",
    "    mean_map = df_train.groupby(col)['Selling Price'].mean()\n",
    "    df_train[f'{col}_target_enc'] = df_train[col].map(mean_map)\n",
    "    df_test[f'{col}_target_enc'] = df_test[col].map(mean_map).fillna(global_mean)\n",
    "\n",
    "# 최종 수치형 데이터셋\n",
    "final_num_cols = ['min_age', 'pack_qty', 'item_weight_lb', 'ship_weight_lb', 'product_vol'] + \\\n",
    "                 [f'{c}_target_enc' for c in target_cols] + \\\n",
    "                 [f'{c}_label' for c in label_cols]\n",
    "\n",
    "print(f\"   -> Numerical Features ({len(final_num_cols)}): {final_num_cols}\")\n",
    "\n",
    "X_num_tr = df_train[final_num_cols].values\n",
    "X_num_te = df_test[final_num_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3246939-62f6-455e-8eee-bdcca2ab4392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. SOTA 임베딩 + PCA + 클러스터링\n",
    "# ==========================================\n",
    "bert = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "def get_advanced_emb(text_list_tr, text_list_te, n_comp, n_cluster):\n",
    "    emb_tr = bert.encode(text_list_tr, show_progress_bar=True, batch_size=64)\n",
    "    emb_te = bert.encode(text_list_te, show_progress_bar=True, batch_size=64)\n",
    "\n",
    "    pca = PCA(n_components=n_comp, random_state=42)\n",
    "    pca_tr = pca.fit_transform(emb_tr)\n",
    "    pca_te = pca.transform(emb_te)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_cluster, random_state=42, n_init=10)\n",
    "    cluster_tr = kmeans.fit_predict(pca_tr).reshape(-1, 1)\n",
    "    cluster_te = kmeans.predict(pca_te).reshape(-1, 1)\n",
    "\n",
    "    return np.hstack([pca_tr, cluster_tr]), np.hstack([pca_te, cluster_te])\n",
    "\n",
    "# 1. Product Name \n",
    "print(\"   -> Processing Product Name...\")\n",
    "tr_n, te_n = get_advanced_emb(df_train['Product Name'].tolist(),\n",
    "                              df_test['Product Name'].tolist(), 64, 20)\n",
    "\n",
    "# 2. Description\n",
    "print(\"   -> Processing Description...\")\n",
    "tr_d, te_d = get_advanced_emb(df_train['Description'].tolist(),\n",
    "                              df_test['Description'].tolist(), 64, 20)\n",
    "\n",
    "# 3. Category + Cleaned_Spec\n",
    "print(\"   -> Processing Category + Spec...\")\n",
    "cats_tr = (df_train['Category'] + \" \" + df_train['Cleaned_Spec']).tolist()\n",
    "cats_te = (df_test['Category'] + \" \" + df_test['Cleaned_Spec']).tolist()\n",
    "tr_c, te_c = get_advanced_emb(cats_tr, cats_te, 64, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce1d94-aca1-431d-9395-f5c1bd6b6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. 저장\n",
    "# ==========================================\n",
    "X_tr = np.hstack([tr_n, tr_d, tr_c, X_num_tr])\n",
    "X_test = np.hstack([te_n, te_d, te_c, X_num_te])\n",
    "\n",
    "print(f\"최종 피처 개수: {X_tr.shape[1]}\")\n",
    "\n",
    "package = {\n",
    "    'X_tr': X_tr,\n",
    "    'y_tr': y_tr,\n",
    "    'X_test': X_test,\n",
    "    'submission': submission,\n",
    "    'feature_names': num_cols + ['emb_pca_...']\n",
    "}\n",
    "save_path = \"data6.pkl\"\n",
    "joblib.dump(package, save_path, compress=3)\n",
    "print(f\"데이터셋 저장: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51bacd-00b3-49c7-885a-c9f7a93cff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 1. 데이터 로드 \n",
    "file_path = 'data6.pkl'\n",
    "\n",
    "try:\n",
    "    data = joblib.load(file_path)\n",
    "    X_tr = data['X_tr']\n",
    "    y_tr = data['y_tr']\n",
    "    X_test = data['X_test']\n",
    "    submission = data['submission']\n",
    "    print(f\"성공! 피처 개수: {X_tr.shape[1]}개\")\n",
    "except FileNotFoundError:\n",
    "    print(\"에러: 파일을 찾을 수 없습니다.\")\n",
    "    exit()\n",
    "\n",
    "# 헬퍼 함수\n",
    "def get_fold_data(X, y, train_idx, val_idx):\n",
    "    if hasattr(X, 'iloc'): X_t, X_v = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    else: X_t, X_v = X[train_idx], X[val_idx]\n",
    "    if hasattr(y, 'iloc'): y_t, y_v = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    else: y_t, y_v = y[train_idx], y[val_idx]\n",
    "    return X_t, X_v, y_t, y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b839d-7984-4e3a-ad63-959b5e84291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ====================================================\n",
    "# 1. 사용자 정의 평가 함수 (Rounded MAE)\n",
    "# ====================================================\n",
    "def eval_rounded_mae_lgb(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    preds = np.round(np.expm1(preds), 2)\n",
    "    actual = np.expm1(labels)\n",
    "    return 'rounded_mae', mean_absolute_error(actual, preds), False\n",
    "    \n",
    "# ====================================================\n",
    "# 2. LightGBM 학습 및 평가 \n",
    "# ====================================================\n",
    "def run_lgbm_final(X, y, X_test, submission_df, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 결과 저장용 배열\n",
    "    oof_preds = np.zeros(X.shape[0])\n",
    "    test_preds = np.zeros(X_test.shape[0])\n",
    "    scores = []\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'None',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 64,\n",
    "        'learning_rate': 0.008,\n",
    "        'feature_fraction': 0.7,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 3,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Log 변환 (타겟)\n",
    "    y_log = np.log1p(y)\n",
    "    \n",
    "    # 피처 중요도 출력을 위한 이름 리스트\n",
    "    feat_names = [f'Feature {i}' for i in range(X.shape[1])]\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        # 데이터 분할 \n",
    "        try:\n",
    "            X_t, X_v, y_t, y_v = get_fold_data(X, y_log, train_idx, val_idx)\n",
    "        except NameError:\n",
    "            X_t, X_v = X[train_idx], X[val_idx]\n",
    "            y_t, y_v = y_log[train_idx], y_log[val_idx]\n",
    "        \n",
    "        train_ds = lgb.Dataset(X_t, label=y_t)\n",
    "        valid_ds = lgb.Dataset(X_v, label=y_v, reference=train_ds)\n",
    "        \n",
    "        # 모델 학습\n",
    "        model = lgb.train(\n",
    "            params, \n",
    "            train_ds, \n",
    "            num_boost_round=100000,\n",
    "            valid_sets=[valid_ds],\n",
    "            feval=eval_rounded_mae_lgb,  # 커스텀 평가 함수 적용\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(2000, verbose=False),\n",
    "                lgb.log_evaluation(1000) \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # 예측 및 역변환\n",
    "        val_pred_log = model.predict(X_v)\n",
    "        test_pred_log = model.predict(X_test)\n",
    "        \n",
    "        val_pred = np.expm1(val_pred_log)\n",
    "        test_pred = np.expm1(test_pred_log)\n",
    "        \n",
    "        oof_preds[val_idx] = val_pred\n",
    "        test_preds += test_pred / n_splits\n",
    "        \n",
    "        # 점수 계산 (반올림 적용된 점수로 기록)\n",
    "        best_score = model.best_score['valid_0']['rounded_mae']\n",
    "        scores.append(best_score)\n",
    "        \n",
    "        print(f\"    -> Fold {fold+1} Best Rounded MAE: {best_score:.4f}\")\n",
    "        \n",
    "    # ==========================================\n",
    "    # 6. 최종 결과 평가 및 저장 로직\n",
    "    # ==========================================\n",
    "    # 1) 원본 OOF 점수\n",
    "    score_final = mean_absolute_error(y, oof_preds)\n",
    "    \n",
    "    # 2) 반올림 적용 OOF 점수\n",
    "    score_rounded = mean_absolute_error(y, np.round(oof_preds, 2))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\" LightGBM Global MAE (Raw): {score_final:.5f}\")\n",
    "    print(f\" 반올림 적용 시 MAE : {score_rounded:.5f}\")\n",
    "    \n",
    "    use_rounding = False\n",
    "    if score_rounded < score_final:\n",
    "        print(\"반올림(소수점 2자리)이 더 유리하여 적용했음.\")\n",
    "        use_rounding = True\n",
    "    else:\n",
    "        print(\"반올림하지 않는 것이 더 좋음.\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 최종 예측값 후처리\n",
    "    final_preds = np.maximum(0.01, test_preds) # 음수 방지\n",
    "    \n",
    "    if use_rounding:\n",
    "        final_preds = np.round(final_preds, 2)\n",
    "        final_score_str = f\"{score_rounded:.4f}\"\n",
    "    else:\n",
    "        final_score_str = f\"{score_final:.4f}\"\n",
    "    \n",
    "    # 파일 저장\n",
    "    save_filename = f'LGBM_Best_MAE_{final_score_str}.csv'\n",
    "    submission_df['Selling Price'] = final_preds\n",
    "    submission_df.to_csv(save_filename, index=False)\n",
    "    print(f\"\\n 파일 저장 완료: {save_filename}\")\n",
    "    \n",
    "    return final_preds\n",
    "final_results = run_lgbm_final(X_tr, y_tr, X_test, submission)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
